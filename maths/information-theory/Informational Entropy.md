---
aliases:
  - Entropy
  - Information
---
A key measure in [[Information Theory]], it quantifies the amount of [[Uncertainty]] involved in the value of a [[randomness|random]] value.

For example a fair coin flip provides less information (less entropy) than a roll of a fair six-face die.
