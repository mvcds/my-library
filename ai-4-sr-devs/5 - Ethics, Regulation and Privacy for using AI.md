[[Risk|Risks]] when using [[Artificially Intelligent Agent|Agents]] exist, we need to understand the [[Ethics]], regulations and [[Privacy]] concerns about using it.

---

To comply with [[General Data Protection Regulation|GDPR]]  in terms of [[Artificially Intelligent Agent|Agents]], we should

- [[carreer/development/design/Design|Design]] [[Privacy]] into the [[Software]]
- Make [[User|Users]] aware of how automated decisions are taken, if that affects them
- Be responsable for [[Transparency]] in the [[Sofware Development Life Cycle|SDLC]]

---

Different [[country|countries]] have different laws regarding [[Artificially Intelligent Agent|Agents]], those laws reflect their [[culture]], [[Politics]], and [[Economy]] [[philosofy/Value|Value]]

---

Mains [[Risk|Risks]] when using [[Artificially Intelligent Agent|Agents]], we should plan how to mitigate their impact

- [[Hallucination|Hallucinations]]
	- Human [[inteligence]] is not perfect
	- Evolution-wise, we use [[heuristic|heuristics]], [[Artificial Intelligence|AI]] also uses [[heuristic|heuristics]]
	- Using [[LLM Settings]] helps to control this
- [[Privacy]]
	- [[Business|Enterprise]] [[Domain Model|Models]] have this baked in
	- Anonymising [[Personal Private Information|PPI]]
- [[carreer/development/artificial-intelligence/Bias|Biases]]
	- Enrich it with examples
	- Review [[training]]
	- [[Human in-the loop]]

---

Main concerns about [[Risk]]

- Exposing the [[Code|Codebase]] to third parties
- Leakage of [[Credential|credentials]]
- [[Conformity]] risks: violating author's rights
- [[Shadow LLMs]]: unnoficial or unallowed tools that will be used within an [[Business|Organization]]
- Malicious Code
- [[Hallucination]]

---

Best [[Security]] practice working with [[Large Language Model|LLMs]]

- De-identification: removing [[Personal Private Information|PPI]] during [[fine tuning]] or [[training]]
- Use fictional [[carreer/development/Value|values]]: if [[training]] requires sensible information
	- Less risk or leaking real [[Information]]
	- Better [[Quality]] of [[Data]]
	- Remove [[culture|cultural]] [[carreer/development/artificial-intelligence/Bias|Bias]]
- Execute [[Large Language Model|LLM]] locally

---

Executing [[Large Language Model|LLMs]] locally

- [[Cost]] is reduced
- No [[Internet]] required
- Totally private

---

Mini [[Model|Models]]

A [[Large Language Model|LLM]] model made for a niche allows for optimising functionality using a smaller size, due to the high specialization

---

Always go back to the basics, mainly including [[Use Case|Use Cases]] that involve [[Artificially Intelligent Agent|Agents]] failing