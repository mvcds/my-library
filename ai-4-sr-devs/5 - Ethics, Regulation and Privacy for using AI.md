[[Risk|Risks]] when using [[Artificially Intelligent Agent|Agents]] exist, we need to understand the [[Ethics]], regulations and [[Privacy]] concerns about using it.

---

To comply with [[General Data Protection Regulation|GDPR]]  in terms of [[Artificially Intelligent Agent|Agents]], we should

- [[carreer/development/design/Design|Design]] [[Privacy]] into the [[Software]]
- Make [[User|Users]] aware of how automated decisions are taken, if that affects them
- Be responsable for [[Transparency]] in the [[Sofware Development Life Cycle|SDLC]]

---

Different [[country|countries]] have different laws regarding [[Artificially Intelligent Agent|Agents]], those laws reflect their [[culture]], [[Politics]], and [[Economy]] [[philosofy/Value|Value]]

---

Mains [[Risk|Risks]] when using [[Artificially Intelligent Agent|Agents]], we should plan how to mitigate their impact

- [[Hallucination|Hallucinations]]
	- Human [[inteligence]] is not perfect
	- Evolution-wise, we use [[heuristic|heuristics]], [[Artificial Intelligence|AI]] also uses [[heuristic|heuristics]]
	- Using [[LLM Settings]] helps to control this
- [[Privacy]]
	- [[Business|Enterprise]] [[Domain Model|Models]] have this baked in
	- Anonymising [[Personal Private Information|PPI]]
- [[Bias|Biases]]
	- Enrich it with examples
	- Review [[training]]
	- [[Human in-the loop]]

---

Main concerns about [[Risk]]

- Exposing the [[Code|Codebase]] to third prties
- Leakage of [[Credential|credentials]]
- [[Conformity]] risks: violating author's rights
- [[Shadow LLMs]]: unnoficial or unallowed tools that will be used within an [[Business|Organization]]
- Malicious Code
- [[Hallucination]]